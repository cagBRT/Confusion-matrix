{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "confusionMatrix1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMIqwknN3tzpsu82Vx3anXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Confusion-matrix/blob/master/confusionMatrix1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97MJzGRmDGl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Confusion-matrix.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAh8c8TWDL3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    return Image(\"confusionMatrix\"+str(num)+ \".png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwIYuS6jqeJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python script for confusion matrix creation.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1PE4Kuw-5wS",
        "colab_type": "text"
      },
      "source": [
        "**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnEk2aY39c4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = [2, 0, 2, 2, 0, 1] #ground truth\n",
        "y_pred = [0, 0, 2, 2, 0, 2] #prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD9fr4KC-99U",
        "colab_type": "text"
      },
      "source": [
        "**The confusion matrix**<br>\n",
        "Cndarray of shape (n_classes, n_classes)<br>\n",
        "Confusion matrix whose i-th row and j-th column entry indicates the number of <br>samples with true label being i-th class and prediced label being j-th class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC2A_6yj-4lZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLYcI18JDbSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOyyezi9F6rb",
        "colab_type": "text"
      },
      "source": [
        "The total of the values in the confusion matrix equals the total number of predictions made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohLU8qhsDmg0",
        "colab_type": "text"
      },
      "source": [
        "**Quiz 1**<br>\n",
        "confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])<br>\n",
        ">[[2,0,1]<br>\n",
        "[0,0,1]<br>\n",
        "[1,0,3]]<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URyfI4btEHfJ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title How many times was a cat mislabeled as an ant or bird?\n",
        "ant_wrong =  5#@param {type:\"integer\"}\n",
        "if(ant_wrong == 1):\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1aeYxzOFQ5w",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title How many times was an ant mislabeled as an cat or bird?\n",
        "cat_wrong =  5#@param {type:\"integer\"}\n",
        "if(cat_wrong == 1):\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0USUzkJPFnmb",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title How many times was a bird mislabeled as an ant or cat?\n",
        "bird_wrong =  5#@param {type:\"integer\"}\n",
        "if(bird_wrong == 1):\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUKpvpncDod5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\",\"cat\",\"ant\"]\n",
        "y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\", \"cat\",\"cat\"]\n",
        "confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ_UGFxMEJRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3GsNhTTIK1W",
        "colab_type": "text"
      },
      "source": [
        "**Quiz 2**<br>\n",
        "The model is predicting whether the image is of a cat or not. \n",
        "\n",
        "Actual values =    [‘dog’, ‘cat’, ‘dog’, ‘cat’, ‘dog’, ‘dog’, ‘cat’, ‘dog’, ‘cat’, ‘dog’]<br>\n",
        "Predicted values = [‘dog’, ‘dog’, ‘dog’, ‘cat’, ‘dog’, ‘dog’, ‘cat’, ‘cat’, ‘cat’, ‘cat’]<br>\n",
        "<br>\n",
        "We describe predicted values as Positive/Negative and actual values as True/False.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEsWecbPEuMG",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title How many True Positives?\n",
        "tp = 0 #@param {type:\"integer\"}\n",
        "if tp==3:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79FcRflAFL7b",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title How many True Negatives?\n",
        "tp = 0 #@param {type:\"integer\"}\n",
        "if tp==4:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_zw7_6CFlyT",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title How many False Positives?\n",
        "tp = 0 #@param {type:\"integer\"}\n",
        "if tp==2:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3WuZyQuFqmA",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title How many False Negatives?\n",
        "tp = 0 #@param {type:\"integer\"}\n",
        "if tp==1:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnNfqGdUbyMC",
        "colab_type": "text"
      },
      "source": [
        "# **Accuracy:** <br>\n",
        "Gives an overall accuracy of the model, meaning the fraction of the total samples that were correctly classified by the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C72BJ1vaE11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl7XBtlrakRg",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title What is the accuracy for the Cat Identification Model? (In decimal format)\n",
        "accuracy =  0.8#@param {type:\"number\"}\n",
        "if accuracy == .7:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWizwiRpiats",
        "colab_type": "text"
      },
      "source": [
        "# **Recall (aka Sensitivity):**<br>\n",
        "\n",
        "Recall is defined as the ratio of the total number of correctly classified positive classes divide by the total number of positive classes. Or, out of all the positive classes, how much we have predicted correctly. <br>\n",
        "<br>**Recall should be high.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtR6f0Uia_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOfrW52MkcVg",
        "colab_type": "text"
      },
      "source": [
        "**Quiz 3**<br>\n",
        "What is the recall for the Cat identification model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48LWPehBknWw",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title What is the recall for cat in the Cat Model?\n",
        "recall =  0.75#@param {type:\"number\"}\n",
        "if recall == .75:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZlOpCTOr4hL",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title What is the recall for dog in the Cat Model?\n",
        "recall =  0.75#@param {type:\"number\"}\n",
        "if recall == .67:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wScHTF79lSia",
        "colab_type": "text"
      },
      "source": [
        "# **Precision:**\n",
        "Precision is defined as the ratio of the total number of correctly classified positive classes divided by the total number of predicted positive classes. Or, out of all the predictive positive classes, how much we predicted correctly.<br>\n",
        " \n",
        " **Precision should be high.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-uGjA1RnKPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uEdy-85lbzS",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title What is the precision for cats in the Cat Model?\n",
        "precision =  0#@param {type:\"number\"}\n",
        "if precision == .6:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try Again\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NssUYP1xq9ZF",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title What is the precision for dogs in the Cat Model?\n",
        "precision =  0#@param {type:\"number\"}\n",
        "if precision == .8:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try Again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko9eSC-tmz1C",
        "colab_type": "text"
      },
      "source": [
        "# **F-score or F1-score**:\n",
        "It is difficult to compare two models with different Precision and Recall. So to make them comparable, we use F-Score. It is the Harmonic Mean of Precision and Recall. As compared to Arithmetic Mean, Harmonic Mean punishes the extreme values more. <br>\n",
        "**F-score should be high.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4D7PtDbm0F-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTHhHFS7naCT",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title What is the F-score for the cat in the Cat Model?\n",
        "fscore =  0#@param {type:\"number\"}\n",
        "if fscore == 0.67:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try Again\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tulc00C6sBYE",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title What is the F-score for the dog in the Cat Model?\n",
        "fscore =  0#@param {type:\"number\"}\n",
        "if fscore == 0.73:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try Again\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xxl6Bc6oP3f",
        "colab_type": "text"
      },
      "source": [
        "# **Specificity:**\n",
        "Specificity determines the proportion of actual negatives that are correctly identified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfEG7dHIoSLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AtRwf5QoWtG",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title What is the Specificity of the Cat Model?\n",
        "specificity = 0 #@param {type:\"number\"}\n",
        "if specificity== 0.67:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try Again\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loUEyLuaqads",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual = ['dog','cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat']\n",
        "predicted = ['dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat']\n",
        "results = confusion_matrix(actual, predicted)\n",
        "print ('Confusion Matrix :')\n",
        "print(results)\n",
        "print ('Accuracy Score :',accuracy_score(actual, predicted))\n",
        "print('Classification Report : ')\n",
        "print (classification_report(actual, predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU5IBzyZsmrg",
        "colab_type": "text"
      },
      "source": [
        "**Precision** is how certain you are of your true positives. Recall is how certain you are that you are not missing any positives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKgTzNFvsp9K",
        "colab_type": "text"
      },
      "source": [
        "Choose **Recall** if the occurrence of false negatives is unaccepted/intolerable. For example, in the case of diabetes that you would rather have some extra false positives (false alarms) over saving some false negatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di9LRmauswUr",
        "colab_type": "text"
      },
      "source": [
        "Choose **Precision** if you want to be more confident of your true positives. For example, in case of spam emails, you would rather have some spam emails in your inbox rather than some regular emails in your spam box. You would like to be extra sure that email X is spam before we put it in the spam box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sURyBLgfs63p",
        "colab_type": "text"
      },
      "source": [
        "Choose **Specificity** if you want to cover all true negatives, i.e. meaning we do not want any false alarms or false positives. For example, in case of a drug test in which all people who test positive will immediately go to jail, you would not want anyone drug-free going to jail."
      ]
    }
  ]
}