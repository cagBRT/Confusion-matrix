{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "confusionMatrix2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNRgSGdAIiYGLhHL/SvGN6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Confusion-matrix/blob/master/confusionMatrix2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX-axbT-uWtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Confusion-matrix.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9iSAAVRuZUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    return Image(\"confusionMatrix\"+str(num)+ \".png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIdd3kd5ueCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python script for confusion matrix creation.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvlmLJOStpNI",
        "colab_type": "text"
      },
      "source": [
        "# **The Confusion Matrix for Multi-Class Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xmFESlJt3oh",
        "colab_type": "text"
      },
      "source": [
        "For example: there is a dataset that has three class labels, \n",
        "<br>\n",
        ">Apple, Orange and Mango"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKzZdz4vvN-U",
        "colab_type": "text"
      },
      "source": [
        "In multiclassification there are no positive or negative classes.<br>\n",
        "Find TP, TN, FP and FN for each individual class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS7V95wPtR-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_j4caFDvMjb",
        "colab_type": "text"
      },
      "source": [
        "**For the Apple class:**\n",
        ">TP = 7<br>\n",
        "TN = (2+3+2+1) = 8<br>\n",
        "FP = (8+9) = 17<br>\n",
        "FN = (1+3) = 4<br>\n",
        "<br><br>\n",
        "The total of these stats should equal the total number of predictions made. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJipbd6Lw2Gq",
        "colab_type": "text"
      },
      "source": [
        "**Quiz 1:**<br>\n",
        "Calculate TP, TN,FP,FN for the Orange class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld57cO-nxAFb",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the stats for the Orange class, separate each answer with a space\n",
        "import re\n",
        "stats = \"\" #@param {type:\"string\"}\n",
        "\n",
        "x = re.search(\"2\\s8\\s4\\s10\", stats)\n",
        "x1= re.search(\"2\\s*,\\s*8\\s*,\\s*4\\s*,\\s*10\", stats)\n",
        "if x or x1:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76mAacy1GrjH",
        "colab_type": "text"
      },
      "source": [
        "**Quiz 2:**<br>\n",
        "Calculate TP, TN,FP,FN for the Mango class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_5J2cmWGrtn",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the stats for the Mango class, separate each answer with a space\n",
        "import re\n",
        "stats = \"\" #@param {type:\"string\"}\n",
        "\n",
        "x = re.search(\"1\\s18\\s5\\s12\", stats)\n",
        "x1= re.search(\"1\\s*,\\s*18\\s*,\\s*4\\s*,\\s*12\", stats)\n",
        "if x or x1:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrfYUDZLWRQK",
        "colab_type": "text"
      },
      "source": [
        "# **Precision, Recall, F1-score**\n",
        "\n",
        "Recall the equations for precision, recall, and F1-score. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv9_OulkWfFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKCkxbDcWf2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VObAL7ZLWgAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdE8XdbjXMsk",
        "colab_type": "text"
      },
      "source": [
        "**Quiz 3**\n",
        "Calculate precision, recall, and f-score for the three classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2AWi69YXUBy",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the precision, recall, f-score for the Apple class, separate each answer with a space\n",
        "import re\n",
        "stats = \"\" #@param {type:\"string\"}\n",
        "\n",
        "x = re.search(\"0.29\\s*0.64\\s*0.4\", stats)\n",
        "x1= re.search(\"0.29\\s*,\\s*0.64\\s*,\\s*0.4\", stats)\n",
        "x2 = re.search(\".29\\s*.64\\s*.4\", stats)\n",
        "x3= re.search(\".29\\s*,\\s*.64\\s*,\\s*.4\", stats)\n",
        "\n",
        "if x or x1 or x2 or x3 :\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nos_WY9VYdnB",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the precision, recall, f-score for the Orange class, separate each answer with a space\n",
        "import re\n",
        "stats = \"\" #@param {type:\"string\"}\n",
        "\n",
        "x = re.search(\"0.33\\s*0.17\\s*0.22\", stats)\n",
        "x1= re.search(\"0.33\\s*,\\s*0.17\\s*,\\s*0.22\", stats)\n",
        "x2 = re.search(\".33\\s*.17\\s*.22\", stats)\n",
        "x3= re.search(\".33\\s*,\\s*.17\\s*,\\s*.22\", stats)\n",
        "\n",
        "if x or x1 or x2 or x3 :\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk_3Olf-YzGB",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the precision, recall, f-score for the Mango class, separate each answer with a space\n",
        "import re\n",
        "stats = \"\" #@param {type:\"string\"}\n",
        "\n",
        "x = re.search(\"0.17\\s*0.08\\s*0.11\", stats)\n",
        "x1= re.search(\"0.17\\s*,\\s*0.08\\s*,\\s*0.11\", stats)\n",
        "x2 = re.search(\".17\\s*.08\\s*.11\", stats)\n",
        "x3= re.search(\".17\\s*,\\s*.08\\s*,\\s*.11\", stats)\n",
        "\n",
        "if x or x1 or x2 or x3 :\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S69ZUTljoFN",
        "colab_type": "text"
      },
      "source": [
        "# **F1-Score for Multi-class models**<br>\n",
        "Combining the F1-score of each class to have a single measure for the whole model.<br>\n",
        "There are several methods to combine the F1-scores:<br>\n",
        ">Micro F1<br>\n",
        "Macro F1<br>\n",
        "Weighted F1<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PqcGVQXq1w1",
        "colab_type": "text"
      },
      "source": [
        "**Micro F1**<br>\n",
        "\n",
        "The micro-averaged F1-score is calculated by considering the total TP, total FP and total FN of the model. It does not consider each class individually, It calculates the metrics globally.<br>\n",
        "For example: <br>\n",
        ">TP-global = TP-apple + TP-orange + TP-mango"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB7_kDCMqvvr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the Global TP score\n",
        "import re\n",
        "stats = \"\" #@param {type:\"string\"}\n",
        "\n",
        "x = re.search(\"10\", stats)\n",
        "\n",
        "if x:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEbSiuuWranH",
        "colab_type": "text"
      },
      "source": [
        "Global FPs and FNs are calculated the same way. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH_m0qPfsSSy",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the Global FPs and FNs score. Separate each by space\n",
        "import re\n",
        "stats = \"\" #@param {type:\"string\"}\n",
        "\n",
        "x = re.search(\"26\\s*26\", stats)\n",
        "\n",
        "if x:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rLlR5vBtaz_",
        "colab_type": "text"
      },
      "source": [
        "# **Calculate the Global Precision and Recall, and Micro F1-Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC5nInqztlMb",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the precision, recall, f-score for the Mango class, separate each answer with a space\n",
        "import re\n",
        "stats = \"\" #@param {type:\"string\"}\n",
        "\n",
        "x = re.search(\"0.28\\s*0.28\\s*0.28\", stats)\n",
        "x1= re.search(\"0.28\\s*,\\s*0.28\\s*,\\s*0.28\", stats)\n",
        "x2 = re.search(\".28\\s*.28\\s*.28\", stats)\n",
        "x3= re.search(\".28\\s*,\\s*.28\\s*,\\s*.28\", stats)\n",
        "\n",
        "if x or x1 or x2 or x3 :\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR2upVtkwwAC",
        "colab_type": "text"
      },
      "source": [
        "When calculating the metrics globally all the measures become equal<br>\n",
        "**Precision = Recall = Micro F1 = Accuracy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YdQgb7aw1Gr",
        "colab_type": "text"
      },
      "source": [
        "# **Macro F1**\n",
        "This is the macro-averaged F1-score. <br>\n",
        "It calculates metrics for each class individually and then takes unweighted mean of the measures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4AQ_dn75vD3",
        "colab_type": "text"
      },
      "source": [
        "Macro F1 = Average of the F1-scores<br>\n",
        "For example:<br>\n",
        "\n",
        ">Macro F1 = (F1-apple + F1-oragne + F1-mango)/3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIhN5Rc15e6e",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the Macro F1-score\n",
        "stats =  0#@param {type:\"number\"}\n",
        "\n",
        "if stats == 0.24:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")\n",
        "#Macro F1 = (0.40+0.22+0.11)/3 = 0.24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzIFLf-U7Ckm",
        "colab_type": "text"
      },
      "source": [
        "# **Weighted Average F1 Score**<br>\n",
        "\n",
        "The last one is weighted-averaged F1-score. <br>\n",
        "Unlike Macro F1, it takes a weighted mean of the measures. <br>\n",
        "The weights for each class are the total number of samples of that class. <br>\n",
        "For example:<br>\n",
        "We have 11 Apples, 12 Oranges and 13 Mangoes,<br>\n",
        "\n",
        ">Weighted-ave F1 = ((F1-apple * 11)+(F1-orange * 12)+(F1-mango*13))/(11+12+13) = 0.24"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgn82bOA7hop",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calcualte the Weighted Average F1-score\n",
        "stats =  0#@param {type:\"number\"}\n",
        "\n",
        "if stats == 0.24:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Try again\")\n",
        "#Weighted F1 = ((0.40*11)+(0.22*12)+(0.11*13))/(11+12+13) = 0.24"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}